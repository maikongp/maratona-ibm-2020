{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "94GO0QdvfTlw",
        "Otjeen7kfTnj",
        "aF61we-1fToP",
        "mZ9fTqIMfToq",
        "xsAzVa_zfToz",
        "5Yjz1foDfTpn",
        "SuWfBjc7fTqQ",
        "vnbDmC-wfTqw",
        "yivgm0zWfTq5"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyN6Z5hDfTkT"
      },
      "source": [
        "# @hidden_cell\n",
        "# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\n",
        "from project_lib import Project\n",
        "project = Project(project_id='', project_access_token='')\n",
        "pc = project.project_context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "xaONJw89fTkd"
      },
      "source": [
        "# MARATONA BEHIND THE CODE 2020\n",
        "\n",
        "## DESAFIO 2: UNINASSAU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCa2sXunfTkf"
      },
      "source": [
        "### Instalando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4KpedNJfTkh"
      },
      "source": [
        "!pip install scikit-learn --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZDxHP49fTkt"
      },
      "source": [
        "!pip install xgboost --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIygJdIQfTk5"
      },
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z9kwJtDfTlD"
      },
      "source": [
        "# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n",
        "\n",
        "# Pacote para trabalhar com JSON\n",
        "import json\n",
        "\n",
        "# Pacote para realizar requisições HTTP\n",
        "import requests\n",
        "\n",
        "# Pacote para exploração e análise de dados\n",
        "import pandas as pd\n",
        "\n",
        "# Pacote com métodos numéricos e representações matriciais\n",
        "import numpy as np\n",
        "\n",
        "# Pacote para construção de modelo baseado na técnica Gradient Boosting\n",
        "import xgboost as xgb\n",
        "\n",
        "# Pacotes do scikit-learn para pré-processamento de dados\n",
        "# \"SimpleImputer\" é uma transformação para preencher valores faltantes em conjuntos de dados\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Pacotes do scikit-learn para treinamento de modelos e construção de pipelines\n",
        "# Método para separação de conjunto de dados em amostras de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Método para criação de modelos baseados em árvores de decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Classe para a criação de uma pipeline de machine-learning\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Pacotes do scikit-learn para avaliação de modelos\n",
        "# Métodos para validação cruzada do modelo criado\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tau55hdQfTlL"
      },
      "source": [
        "## Download dos conjuntos de dados em formato .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLWXnHMSfTlN"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/maratonadev-br/desafio-2-2020/master/Assets/Data/dataset_desafio_2.csv\n",
        "df_training_dataset = pd.read_csv(r'dataset_desafio_2.csv')\n",
        "df_training_dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TlzOe-ufTlX"
      },
      "source": [
        "Temos 15 colunas presentes no dataset fornecido, sendo dezessete delas variáveis características (dados de entrada) e um delas uma variável-alvo (que queremos que o nosso modelo seja capaz de prever). \n",
        "\n",
        "As variáveis características são:\n",
        "\n",
        "    MATRICULA       - número de matrícula do estudante\n",
        "    NOME            - nome completo do estudante\n",
        "    REPROVACOES_DE  - número de reprovações na disciplina de ``Direito Empresarial``\n",
        "    REPROVACOES_EM  - número de reprovações na disciplina de ``Empreendedorismo``\n",
        "    REPROVACOES_MF  - número de reprovações na disciplina de ``Matemática Financeira``\n",
        "    REPROVACOES_GO  - número de reprovações na disciplina de ``Gestão Operacional``\n",
        "    NOTA_DE         - média simples das notas do aluno na disciplina de ``Direito Empresarial`` (0-10)\n",
        "    NOTA_EM         - média simples das notas do aluno na disciplina de ``Empreendedorismo`` (0-10)\n",
        "    NOTA_MF         - média simples das notas do aluno na disciplina de ``Matemática Financeira`` (0-10)\n",
        "    NOTA_GO         - média simples das notas do aluno na disciplina de ``Gestão Operacional`` (0-10)\n",
        "    INGLES          - variável binária que indica se o estudante tem conhecimento em língua inglesa (0 -> sim ou 1 -> não).\n",
        "    H_AULA_PRES     - horas de estudo presencial realizadas pelo estudante\n",
        "    TAREFAS_ONLINE  - número de tarefas online entregues pelo estudante\n",
        "    FALTAS          - número de faltas acumuladas do estudante (todas disciplinas)\n",
        "    \n",
        "A variável-alvo é:\n",
        "\n",
        "    PERFIL               - uma *string* que indica uma de cinco possibilidades: \n",
        "        \"EXCELENTE\"      - Estudante não necessita de mentoria\n",
        "        \"MUITO BOM\"      - Estudante não necessita de mentoria\n",
        "        \"HUMANAS\"        - Estudante necessita de mentoria exclusivamente em matérias com conteúdo de ciências humanas\n",
        "        \"EXATAS\"         - Estudante necessita de mentoria apenas em disciplinas com conteúdo de ciências exatas\n",
        "        \"DIFICULDADE\"    - Estudante necessita de mentoria em duas ou mais disciplinas\n",
        "        \n",
        "Com um modelo capaz de classificar um estudante em uma dessas categorias, podemos automatizar parte da mentoria estudantil através de assistentes virtuais, que serão capazes de recomendar práticas de estudo e conteúdo personalizado com base nas necessidades de cada aluno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtpFdDZSfTlY"
      },
      "source": [
        "### Explorando os dados fornecidos\n",
        "\n",
        "Podemos continuar a exploração dos dados fornecidos com a função ``info()``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uleGFq73fTlb"
      },
      "source": [
        "df_training_dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp_VenRafTll"
      },
      "source": [
        "É notado que existem variáveis do tipo ``float64`` (números \"decimais\"), variáveis do tipo ``int64`` (números inteiros) e do tipo ``object`` (nesse caso são *strings*, ou texto). \n",
        "\n",
        "Como a maioria dos algoritmos de aprendizado estatístico supervisionado só aceita valores numéricos como entrada, é necessário então o pré-processamento das variáveis do tipo \"object\" antes de usar esse dataset como entrada para o treinamento de um modelo. Também é notado que existem valores faltantes em várias colunas. Esses valores faltantes também devem ser tratados antes de serem construídos modelos com esse conjunto de dados base."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV7oW25kfTlm"
      },
      "source": [
        "A função ``describe()`` gera várias informações sobre as variáveis numéricas que também podem ser úteis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF6gkfC0fTlo"
      },
      "source": [
        "df_training_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94GO0QdvfTlw"
      },
      "source": [
        "### Visualizações\n",
        "\n",
        "Para visualizar o dataset fornecido, podemos utilizar as bibliotecas ``matplotlib`` e ``seaborn``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtqFPmKmfTlx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm0SbwcmfTl4"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.countplot(ax=axes[0], x='REPROVACOES_DE', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[1], x='REPROVACOES_EM', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[2], x='REPROVACOES_MF', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[3], x='REPROVACOES_GO', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uid_fY0OfTmC"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.distplot(df_training_dataset['NOTA_DE'], ax=axes[0])\n",
        "sns.distplot(df_training_dataset['NOTA_EM'], ax=axes[1])\n",
        "sns.distplot(df_training_dataset['NOTA_MF'], ax=axes[2])\n",
        "sns.distplot(df_training_dataset['NOTA_GO'].dropna(), ax=axes[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "f1KAuXWNfTmO"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.countplot(ax=axes[0], x='INGLES', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[1], x='FALTAS', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[2], x='H_AULA_PRES', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[3], x='TAREFAS_ONLINE', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHqIN2WIfTmW"
      },
      "source": [
        "fig = plt.plot()\n",
        "sns.countplot(x='PERFIL', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zMAI7h8fTmf"
      },
      "source": [
        "## ** ATENÇÃO **\n",
        "\n",
        "Você pode notar pela figura acima que este dataset é desbalanceado, isto é, a quantidade de amostras para cada classe que desejamos classificar é bem discrepante. O participante é livre para adicionar ou remover **LINHAS** no dataset fornecido, inclusive utilizar bibliotecas para balanceamento com ``imblearn``.\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-DkiBNufTmg"
      },
      "source": [
        "## Pré-processamento dos dados (Maikon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd6KEDn-fTmi"
      },
      "source": [
        "## Transformação 1 - Remover os alunos com todas as notas zeradas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5mS-jbOfTml"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# All sklearn Transforms must have the `transform` and `fit` methods\n",
        "class DropStudents(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, min_grade):\n",
        "        self.min_grade = min_grade\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Primeiro realizamos uma cópia do dataframe 'X' de entrada\n",
        "        data = X.copy()\n",
        "        # Remove os alunos que possuem todas as notas menores ou iguais a nota miníma.\n",
        "        data = data[~((data['NOTA_DE'] <= self.min_grade) & (data['NOTA_EM'] <= self.min_grade) \n",
        "                      & (data['NOTA_MF'] <= self.min_grade) & (data['NOTA_GO'] <= self.min_grade))]\n",
        "        \n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJeI8IVwfTmr"
      },
      "source": [
        "# Essa transformação recebe como parâmetro o valor da nota mínima do estudante em todas as disciplinas.\n",
        "drop_students = DropStudents(min_grade=0)\n",
        "\n",
        "# Aplicando a transformação ``DropStudents`` ao conjunto de dados base\n",
        "drop_students.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_training_dataset = pd.DataFrame.from_records(data=drop_students.transform(X=df_training_dataset),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXAXxG49fTm3"
      },
      "source": [
        "## Transformação 2 - Coluna Notas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJAZ3kT_fTm5"
      },
      "source": [
        "Na coluna \"NOTA_MF\" existiam valores maiores que 10 pontos (a pontuação máxima), sendo assim, estas notas serão ajustadas para ficarem entre 0 a 10 pontos. Na coluna \"NOTA_GO\" existiam valores nulos. Elas serão subsituidas pela mediana."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z6OOQ6GfTm6"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# All sklearn Transforms must have the `transform` and `fit` methods\n",
        "class FitGradeColumns(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Primeiro realizamos uma cópia do dataframe 'X' de entrada\n",
        "        data = X.copy()\n",
        "        # Para cada coluna de notas\n",
        "        for c in self.columns:\n",
        "            #ajusta para 10 pontos se a pontuação for maior que 10.\n",
        "            data[c] = data[c].apply(lambda x: 10 if x > 10 else x)\n",
        "            #ajusta para 0 pontos se a pontuação for menor que 0.\n",
        "            data[c] = data[c].apply(lambda x: 0 if x < 0 else x)  \n",
        "            #ajusta as notas com valores nulos para a mediana do conjunto de notas.\n",
        "            s_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "            #set the grade column\n",
        "            s_imputer.fit(X=data[[c]])\n",
        "            #apply the simple imputer transform\n",
        "            data[c] = s_imputer.transform(X=data[[c]])\n",
        "        \n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvezHT6afTnB"
      },
      "source": [
        "# Essa transformação recebe como parâmetro uma lista com os nomes das colunas de notas.\n",
        "fit_grade_columns = FitGradeColumns(columns=[\"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\"])\n",
        "\n",
        "# Aplicando a transformação ``FitGradeColumns`` ao conjunto de dados base\n",
        "fit_grade_columns.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_training_dataset = pd.DataFrame.from_records(data=fit_grade_columns.transform(X=df_training_dataset),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ENgl9cfTnK"
      },
      "source": [
        "## Transformação 3 - Ajustando outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3SH4kSOfTnL"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# All sklearn Transforms must have the `transform` and `fit` methods\n",
        "# Os outliers serão ajustados utilizando a técnica IQR Score\n",
        "class HandleOutliers(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Primeiro realizamos uma cópia do dataframe 'X' de entrada\n",
        "        data = X.copy()\n",
        "        # Para cada coluna que se deseja remover os outliers\n",
        "        for c in self.columns:            \n",
        "            # Primeiro quartil - representa 25% dos dados\n",
        "            Q1 = data[c].quantile(0.25)\n",
        "            # Terceiro quartil - representa 75% dos dados\n",
        "            Q3 = data[c].quantile(0.75)\n",
        "            #Intervalo inter-quartil (Q3-Q1)\n",
        "            IQR = Q3 - Q1\n",
        "            # Limite máximo\n",
        "            max_lim = Q3 + 1.5 * IQR\n",
        "            # Limite mínimo\n",
        "            min_lim = Q1 - 1.5 * IQR\n",
        "            #Set the limite mínimo\n",
        "            data[c] = data[c].apply(lambda x: min_lim if x < min_lim else x)\n",
        "            #Set the limite máximo\n",
        "            data[c] = data[c].apply(lambda x: max_lim if x > max_lim else x)\n",
        "        \n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfODHb1PfTnR"
      },
      "source": [
        "# Essa transformação recebe como parâmetro uma lista com os nomes das colunas em que se deseja ajustar os outliers\n",
        "outliers = HandleOutliers(columns=[\"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\"])\n",
        "\n",
        "# Aplicando a transformação ``HandleOutliers`` ao conjunto de dados base\n",
        "outliers.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_training_dataset = pd.DataFrame.from_records(data=outliers.transform(X=df_training_dataset),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C82T9WJgfTna"
      },
      "source": [
        "## Analisando os outliers depois do pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U986rk3fTnb"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.boxplot(ax=axes[0], y='NOTA_DE', data=df_training_dataset)\n",
        "sns.boxplot(ax=axes[1], y='NOTA_EM', data=df_training_dataset)\n",
        "sns.boxplot(ax=axes[2], y='NOTA_MF', data=df_training_dataset)\n",
        "sns.boxplot(ax=axes[3], y='NOTA_GO', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMD2M_SIfTnh"
      },
      "source": [
        "## Transformação 4 - Remoção de algumas colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otjeen7kfTnj"
      },
      "source": [
        "#### Transformação 1: excluindo colunas do dataset\n",
        "\n",
        "Para a criação de uma transformação de dados personalizada no scikit-learn, é necessária basicamente a criação de uma classe com os métodos ``transform`` e ``fit``. No método transform será executada a lógica da nossa transformação.\n",
        "\n",
        "Na próxima célula é apresentado o código completo de uma transformação ``DropColumns`` para a remoção de colunas de um DataFrame pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1loL9xu0fTnk"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# All sklearn Transforms must have the `transform` and `fit` methods\n",
        "class DropColumns(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n",
        "        data = X.copy()\n",
        "        # Retornamos um novo dataframe sem as colunas indesejadas\n",
        "        return data.drop(labels=self.columns, axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp5QUf4vfTnt"
      },
      "source": [
        "Para aplicar essa transformação em um DataFrame pandas, basta instanciar um objeto *DropColumns* e chamar o método transform()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW10_qCgfTnv",
        "outputId": "5188544f-ce0a-446b-a5c6-3a3abef9f2e4"
      },
      "source": [
        "# Instanciando uma transformação DropColumns\n",
        "rm_columns = DropColumns(\n",
        "    columns=['MATRICULA', 'NOME', 'REPROVACOES_DE', 'REPROVACOES_EM',\n",
        "       'REPROVACOES_MF', 'REPROVACOES_GO', 'INGLES', 'H_AULA_PRES']  # Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\n",
        ")\n",
        "\n",
        "print(rm_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DropColumns(columns=['MATRICULA', 'NOME', 'REPROVACOES_DE', 'REPROVACOES_EM',\n",
            "                     'REPROVACOES_MF', 'REPROVACOES_GO', 'INGLES',\n",
            "                     'H_AULA_PRES'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7KCCpV8fTn6",
        "outputId": "ad1dd34c-5327-4c21-b8a5-c8fb6cd7f3a6"
      },
      "source": [
        "# Visualizando as colunas do dataset original\n",
        "print(\"Colunas do dataset original: \\n\")\n",
        "print(df_training_dataset.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colunas do dataset original: \n",
            "\n",
            "Index(['MATRICULA', 'NOME', 'REPROVACOES_DE', 'REPROVACOES_EM',\n",
            "       'REPROVACOES_MF', 'REPROVACOES_GO', 'NOTA_DE', 'NOTA_EM', 'NOTA_MF',\n",
            "       'NOTA_GO', 'INGLES', 'H_AULA_PRES', 'TAREFAS_ONLINE', 'FALTAS',\n",
            "       'PERFIL'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zgLShFKfToD"
      },
      "source": [
        "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
        "rm_columns.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_training_dataset = pd.DataFrame.from_records(\n",
        "    data=rm_columns.transform(\n",
        "        X=df_training_dataset\n",
        "    ),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcLe2JbGfToJ",
        "outputId": "8c1530d2-f6c5-466b-9933-a1cff9d39b9e"
      },
      "source": [
        "# Visualizando as colunas do dataset transformado\n",
        "print(\"Colunas do dataset após a transformação ``DropColumns``: \\n\")\n",
        "print(df_training_dataset.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colunas do dataset após a transformação ``DropColumns``: \n",
            "\n",
            "Index(['NOTA_DE', 'NOTA_EM', 'NOTA_MF', 'NOTA_GO', 'TAREFAS_ONLINE', 'FALTAS',\n",
            "       'PERFIL'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF61we-1fToP"
      },
      "source": [
        "#### Transformação 2: tratando dados faltantes\n",
        "\n",
        "Para tratar os dados faltantes em nosso conjunto de dados, iremos agora utilizar uma transformação pronta da biblioteca scikit-learn, chamada **SimpleImputer**.\n",
        "\n",
        "Essa transformação permite diversas estratégias para o tratamento de dados faltantes. A documentação oficial pode ser encontrada em: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
        "\n",
        "Neste exemplo iremos simplesmente transformar todos os valores faltantes em zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrzmENn9fToQ"
      },
      "source": [
        "# Criação de um objeto ``SimpleImputer``\n",
        "si = SimpleImputer(\n",
        "    missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n",
        "    strategy='constant',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n",
        "    fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n",
        "    verbose=0,\n",
        "    copy=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uD-zfHrfToW"
      },
      "source": [
        "# Visualizando os dados faltantes do dataset após a primeira transformação (df_data_2)\n",
        "print(\"Valores nulos antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_2.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5jIe09efTod"
      },
      "source": [
        "# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\n",
        "si.fit(X=df_training_dataset_2)\n",
        "\n",
        "# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\n",
        "df_training_dataset_3 = pd.DataFrame.from_records(\n",
        "    data=si.transform(\n",
        "        X=df_training_dataset_2\n",
        "    ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n",
        "    columns=df_training_dataset_2.columns  # as colunas originais devem ser conservadas nessa transformação\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtsPrtEBfToj"
      },
      "source": [
        "# Visualizando os dados faltantes do dataset após a segunda transformação (SimpleImputer) (df_data_3)\n",
        "print(\"Valores nulos no dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_3.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9m7S4HgfTop"
      },
      "source": [
        "Nota-se que não temos mais nenhum valor faltante no nosso conjunto de dados :)\n",
        "\n",
        "Vale salientar que nem sempre a alteração dos valores faltantes por 0 é a melhor estratégia. O participante é incentivado a estudar e implementar estratégias diferentes de tratamento dos valores faltantes para aprimorar seu modelo e melhorar sua pontuação final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ9fTqIMfToq"
      },
      "source": [
        "### Treinando um modelo de classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTGO6WfrfTor"
      },
      "source": [
        "Finalizado o pré-processamento, já temos o conjunto de dados no formato necessário para o treinamento do nosso modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXb9KcVofTos"
      },
      "source": [
        "df_training_dataset_3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiK2V-IgfToy"
      },
      "source": [
        "No exemplo fornecido, iremos utilizar todas as colunas, exceto a coluna **LABELS** como *features* (variáveis de entrada).\n",
        "\n",
        "A variável **LABELS** será a variável-alvo do modelo, conforme descrito no enunciado do desafio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsAzVa_zfToz"
      },
      "source": [
        "#### Definindo as features do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpDS71bRfTo1"
      },
      "source": [
        "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
        "features = [\n",
        "    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
        "]\n",
        "\n",
        "# Definição da variável-alvo\n",
        "target = [\"PERFIL\"]\n",
        "\n",
        "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
        "X = df_training_dataset[features]\n",
        "y = df_training_dataset[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnkJ0LlOfTo7"
      },
      "source": [
        "O conjunto de entrada (X):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa9lZaLCfTo8",
        "outputId": "013b206c-688d-4e9d-f9c6-c52eb32eb301"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NOTA_DE</th>\n",
              "      <th>NOTA_EM</th>\n",
              "      <th>NOTA_MF</th>\n",
              "      <th>NOTA_GO</th>\n",
              "      <th>TAREFAS_ONLINE</th>\n",
              "      <th>FALTAS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.2</td>\n",
              "      <td>5.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>5.9</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.3</td>\n",
              "      <td>6.7</td>\n",
              "      <td>7.1</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  TAREFAS_ONLINE  FALTAS\n",
              "0      6.2      5.8      4.6      5.9               4       3\n",
              "1      6.0      6.2      5.2      4.5               4       3\n",
              "2      7.3      6.7      7.1      7.2               0       3\n",
              "3      0.0      0.0      0.0      0.0               4       4\n",
              "4      0.0      0.0      0.0      0.0               2       5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAMA1GKdfTpC"
      },
      "source": [
        "As variáveis-alvo correspondentes (y):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN7yT5G7fTpD",
        "outputId": "b4c98431-38d4-4949-9056-6a6d1cc389e7"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PERFIL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EXATAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EXATAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HUMANAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DIFICULDADE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DIFICULDADE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PERFIL\n",
              "0       EXATAS\n",
              "1       EXATAS\n",
              "2      HUMANAS\n",
              "3  DIFICULDADE\n",
              "4  DIFICULDADE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Z9dIHRfTpJ"
      },
      "source": [
        "## Balanceando as classes com oversampling - SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5aWAPslfTpK"
      },
      "source": [
        "smt = SMOTE()\n",
        "\n",
        "X, y = smt.fit_resample(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb1eibFdfTpS"
      },
      "source": [
        "#### Separando o dataset em um conjunto de treino e um conjunto de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBD2hF-OfTpT"
      },
      "source": [
        "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego. A separação do dataset pode ser feita facilmente com o método *train_test_split()* do scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFpnFPvGfTpU"
      },
      "source": [
        "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrCaJg5afTpd"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yjz1foDfTpn"
      },
      "source": [
        "#### Criando um modelo baseado em árvores de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCxltXcjfTpo"
      },
      "source": [
        "No exemplo fornecido iremos criar um classificador baseado em **árvores de decisão**.\n",
        "\n",
        "Material teórico sobre árvores de decisão na documentação oficial do scikit-learn: https://scikit-learn.org/stable/modules/tree.html\n",
        "\n",
        "O primeiro passo é basicamente instanciar um objeto *DecisionTreeClassifier()* da biblioteca scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3xYGS8LfTpq"
      },
      "source": [
        "## Treinando o modelo com o classificador baseado em árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQTXLvOdfTpr"
      },
      "source": [
        "# Criação de uma árvore de decisão com a biblioteca ``scikit-learn``:\n",
        "decision_tree = DecisionTreeClassifier(max_depth=8)\n",
        "\n",
        "# Treino do modelo (é chamado o método *fit()* com os conjuntos de treino)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Realização de teste cego no modelo criado\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "# Acurácia alcançada pela árvore de decisão\n",
        "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))\n",
        "\n",
        "print (classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Oms-2SMfTpx"
      },
      "source": [
        "## Treinando o modelo c/ o algoritmo KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an5BctchfTpy"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realização de teste cego no modelo criado\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Acurácia alcançada pela árvore de decisão\n",
        "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))\n",
        "\n",
        "print (classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrTExaE8fTp8"
      },
      "source": [
        "## Criando um modelo XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X2faEz2fTp9"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xg_boost = XGBClassifier()\n",
        "xg_boost.fit(X_train, y_train)\n",
        "\n",
        "# Realização de teste cego no modelo criado\n",
        "y_pred = xg_boost.predict(X_test)\n",
        "\n",
        "# Acurácia alcançada pela árvore de decisão\n",
        "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))\n",
        "\n",
        "print (classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Tq8IbdfTqL"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Scoring dos dados necessários para entregar a solução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtTUih8kfTqO"
      },
      "source": [
        "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuWfBjc7fTqQ"
      },
      "source": [
        "### Download da \"folha de respostas\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuJEDvFzfTqR",
        "outputId": "d7fd2ac8-0916-4a4f-8fe7-85bc7c008c96"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-uninassau/master/to_be_scored_uninassau.csv\n",
        "df_to_be_scored = pd.read_csv(r'to_be_scored_uninassau.csv')\n",
        "df_to_be_scored.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-06 00:11:09--  https://raw.githubusercontent.com/vanderlei-test/dataset-uninassau/master/to_be_scored_uninassau.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32172 (31K) [text/plain]\n",
            "Saving to: ‘to_be_scored_uninassau.csv.1’\n",
            "\n",
            "100%[======================================>] 32,172      --.-K/s   in 0.001s  \n",
            "\n",
            "2020-09-06 00:11:09 (26.4 MB/s) - ‘to_be_scored_uninassau.csv.1’ saved [32172/32172]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MATRICULA</th>\n",
              "      <th>NOME</th>\n",
              "      <th>REPROVACOES_DE</th>\n",
              "      <th>REPROVACOES_EM</th>\n",
              "      <th>REPROVACOES_MF</th>\n",
              "      <th>REPROVACOES_GO</th>\n",
              "      <th>NOTA_DE</th>\n",
              "      <th>NOTA_EM</th>\n",
              "      <th>NOTA_MF</th>\n",
              "      <th>NOTA_GO</th>\n",
              "      <th>INGLES</th>\n",
              "      <th>H_AULA_PRES</th>\n",
              "      <th>TAREFAS_ONLINE</th>\n",
              "      <th>FALTAS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>940576</td>\n",
              "      <td>Samuel Bahia Cranulunan</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>5.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>682956</td>\n",
              "      <td>Samuel de Linhares</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>850896</td>\n",
              "      <td>Gigi Olga de Oliveira</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>7.1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>525876</td>\n",
              "      <td>Marta Oaman</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>7.2</td>\n",
              "      <td>5.2</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>867666</td>\n",
              "      <td>Eliel Jardel da Costa Sanches</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     MATRICULA                           NOME  REPROVACOES_DE  REPROVACOES_EM  \\\n",
              "495     940576        Samuel Bahia Cranulunan               0               0   \n",
              "496     682956             Samuel de Linhares               0               0   \n",
              "497     850896          Gigi Olga de Oliveira               0               0   \n",
              "498     525876                    Marta Oaman               0               0   \n",
              "499     867666  Eliel Jardel da Costa Sanches               0               0   \n",
              "\n",
              "     REPROVACOES_MF  REPROVACOES_GO  NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  \\\n",
              "495               0               0      6.3      5.3      7.0      5.6   \n",
              "496               0               0      5.7      5.9      5.8      5.0   \n",
              "497               0               0      6.7      7.1      5.7      6.3   \n",
              "498               0               0      6.7      7.2      5.2      5.7   \n",
              "499               0               0      7.1      6.8      6.5      6.0   \n",
              "\n",
              "     INGLES  H_AULA_PRES  TAREFAS_ONLINE  FALTAS  \n",
              "495       1            4               0       8  \n",
              "496       1            1               1       6  \n",
              "497       0           16               6       3  \n",
              "498       1           10               3       5  \n",
              "499       1            5               3       6  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QnJLa03fTqX"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"PERFIL\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daFAzQOIfTqY"
      },
      "source": [
        "df_to_be_scored.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylAGmyxZfTqe"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# Atenção!\n",
        "\n",
        "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
        "\n",
        "# Não remova ou adicione linhas na folha de respostas. \n",
        "\n",
        "# Não altere a ordem das linhas na folha de respostas.\n",
        "\n",
        "# Ao final, as 500 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYGeKpDFfTqf"
      },
      "source": [
        "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvZZ8azKfTqg"
      },
      "source": [
        "# 1 - Não posso aplicar a Transformação 1, pois remove linhas.\n",
        "\n",
        "# 2 - Ajusta as colunas notas (missing values e valor entre 0 e 10)\n",
        "fit_grade_columns = FitGradeColumns(columns=[\"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\"])\n",
        "# Aplicando a transformação ``FitGradeColumns`` ao conjunto de dados base\n",
        "fit_grade_columns.fit(X=df_to_be_scored)\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_to_be_scored_2 = pd.DataFrame.from_records(data=fit_grade_columns.transform(X=df_to_be_scored),)\n",
        "\n",
        "# 3 - Não apliquei o ajuste dos outliers das colunas notas\n",
        "\n",
        "# 4 - Remoção de algumas colunas\n",
        "rm_columns = DropColumns(columns=['MATRICULA', 'NOME', 'REPROVACOES_DE', 'REPROVACOES_EM',\n",
        "       'REPROVACOES_MF', 'REPROVACOES_GO', 'INGLES', 'H_AULA_PRES'])\n",
        "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
        "rm_columns.fit(X=df_to_be_scored_2)\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_to_be_scored_3 = pd.DataFrame.from_records(data=rm_columns.transform(X=df_to_be_scored_2),)\n",
        "\n",
        "df_to_be_scored_3.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4meNcHOfTqm"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZGxPzz9fTqo"
      },
      "source": [
        "df_to_be_scored_3.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnbDmC-wfTqw"
      },
      "source": [
        "### Executando as predições na \"folha de respostas\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8tkzWdhfTqx",
        "outputId": "21dc4d44-f44f-4fd8-af07-10712db49cfb"
      },
      "source": [
        "y_pred = decision_tree.predict(df_to_be_scored_3)\n",
        "df_to_be_scored_3['target'] = y_pred\n",
        "df_to_be_scored_3.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NOTA_DE</th>\n",
              "      <th>NOTA_EM</th>\n",
              "      <th>NOTA_MF</th>\n",
              "      <th>NOTA_GO</th>\n",
              "      <th>TAREFAS_ONLINE</th>\n",
              "      <th>FALTAS</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>6.3</td>\n",
              "      <td>5.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>HUMANAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>5.7</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>EXATAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>6.7</td>\n",
              "      <td>7.1</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>EXATAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>6.7</td>\n",
              "      <td>7.2</td>\n",
              "      <td>5.2</td>\n",
              "      <td>5.7</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>EXATAS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>7.1</td>\n",
              "      <td>6.8</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>EXATAS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  TAREFAS_ONLINE  FALTAS   target\n",
              "495      6.3      5.3      7.0      5.6               0       8  HUMANAS\n",
              "496      5.7      5.9      5.8      5.0               1       6   EXATAS\n",
              "497      6.7      7.1      5.7      6.3               6       3   EXATAS\n",
              "498      6.7      7.2      5.2      5.7               3       5   EXATAS\n",
              "499      7.1      6.8      6.5      6.0               3       6   EXATAS"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yivgm0zWfTq5"
      },
      "source": [
        "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DasxYppvfTq6",
        "outputId": "bcbcacda-08f7-4883-9e74-c3fbdfaac700"
      },
      "source": [
        "project.save_data(file_name=\"results.csv\", data=df_to_be_scored_3.to_csv(index=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'file_name': 'results.csv',\n",
              " 'message': 'File saved to project storage.',\n",
              " 'bucket_name': 'uninassauchallengev20-donotdelete-pr-lkhosvqvhddqzg',\n",
              " 'asset_id': '7e33ae78-5076-4fdd-903a-0ab87da6138e'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvphoS3NfTrD"
      },
      "source": [
        "# Atenção\n",
        "\n",
        "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WUWUY5PfTrE"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Parabéns!\n",
        "\n",
        "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
        "\n",
        "# https://uninassau.maratona.dev\n"
      ]
    }
  ]
}